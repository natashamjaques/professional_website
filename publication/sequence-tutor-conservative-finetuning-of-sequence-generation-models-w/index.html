<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.2.0 for Hugo"><meta name=author content="Natasha Jaques"><meta name=description content="To combine supervised learning on data with reinforcement learning, we pre-train a supervised data prior, and penalize KL-divergence from this model using RL training. This enables effective learning of complex sequence-modeling problems for which we wish to match the data while optimizing external metrics like drug effectiveness. The approach produces compelling results in the disparate domains of music generation and drug discovery."><link rel=alternate hreflang=en-us href=https://natashamjaques.github.io/publication/sequence-tutor-conservative-finetuning-of-sequence-generation-models-w/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#1565c0"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.08f2e04360a1c87f5ad39547c02bf219.css><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/media/icon_hua64261c49917fe48d46061d344453b21_144873_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hua64261c49917fe48d46061d344453b21_144873_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://natashamjaques.github.io/publication/sequence-tutor-conservative-finetuning-of-sequence-generation-models-w/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="Natasha Jaques"><meta property="og:url" content="https://natashamjaques.github.io/publication/sequence-tutor-conservative-finetuning-of-sequence-generation-models-w/"><meta property="og:title" content="Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control | Natasha Jaques"><meta property="og:description" content="To combine supervised learning on data with reinforcement learning, we pre-train a supervised data prior, and penalize KL-divergence from this model using RL training. This enables effective learning of complex sequence-modeling problems for which we wish to match the data while optimizing external metrics like drug effectiveness. The approach produces compelling results in the disparate domains of music generation and drug discovery."><meta property="og:image" content="https://natashamjaques.github.io/publication/sequence-tutor-conservative-finetuning-of-sequence-generation-models-w/featured.png"><meta property="twitter:image" content="https://natashamjaques.github.io/publication/sequence-tutor-conservative-finetuning-of-sequence-generation-models-w/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2017-01-01T00:00:00+00:00"><meta property="article:modified_time" content="2017-01-01T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://natashamjaques.github.io/publication/sequence-tutor-conservative-finetuning-of-sequence-generation-models-w/"},"headline":"Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control","image":["https://natashamjaques.github.io/publication/sequence-tutor-conservative-finetuning-of-sequence-generation-models-w/featured.png"],"datePublished":"2017-01-01T00:00:00Z","dateModified":"2017-01-01T00:00:00Z","author":{"@type":"Person","name":"Natasha Jaques"},"publisher":{"@type":"Organization","name":"Natasha Jaques","logo":{"@type":"ImageObject","url":"https://natashamjaques.github.io/media/icon_hua64261c49917fe48d46061d344453b21_144873_192x192_fill_lanczos_center_3.png"}},"description":"To combine supervised learning on data with reinforcement learning, we pre-train a supervised data prior, and penalize KL-divergence from this model using RL training. This enables effective learning of complex sequence-modeling problems for which we wish to match the data while optimizing external metrics like drug effectiveness. The approach produces compelling results in the disparate domains of music generation and drug discovery."}</script><title>Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control | Natasha Jaques</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=8cef86ccf73c40add7c4a7f10f447087><script src=/js/wowchemy-init.min.4be02a3b391999348b0c7478778a0e4b.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Natasha Jaques</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Natasha Jaques</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#awards><span>Awards</span></a></li><li class=nav-item><a class=nav-link href=/#press><span>Press</span></a></li><li class=nav-item><a class=nav-link href=/#featured><span>Featured</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#tags><span>Topics</span></a></li><li class=nav-item><a class=nav-link href=/#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/#communities><span>Communities</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item d-none d-lg-inline-flex"><a class=nav-link href=https://twitter.com/natashajaques data-toggle=tooltip data-placement=bottom title=Twitter target=_blank rel=noopener aria-label=Twitter><i class="fab fa-twitter" aria-hidden=true></i></a></li><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control</h1><div class=article-metadata><div><span class=author-highlighted>Natasha Jaques</span>, <span>S. Gu</span>, <span>D. Bahdanau</span>, <span>J. M. Hernandez-Lobato</span>, <span>R. E. Turner</span>, <span>D. Eck</span></div><span class=article-date>2017</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/abs/1611.02796 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/sequence-tutor-conservative-finetuning-of-sequence-generation-models-w/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header" href=https://github.com/tensorflow/magenta/tree/master/magenta/models/rl_tuner target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header" href=https://vimeo.com/240608475 target=_blank rel=noopener>ICML talk</a>
<a class="btn btn-outline-primary btn-page-header" href=https://youtu.be/abBfZB5DlSY target=_blank rel=noopener>Generated music</a>
<a class="btn btn-outline-primary btn-page-header" href=https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning target=_blank rel=noopener>Magenta blog</a>
<a class="btn btn-outline-primary btn-page-header" href=https://www.technologyreview.com/2016/11/30/155729/ai-songsmith-cranks-out-surprisingly-catchy-tunes/ target=_blank rel=noopener>MIT Tech Review article</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:291px><div style=position:relative><img src=/publication/sequence-tutor-conservative-finetuning-of-sequence-generation-models-w/featured_hucb3b8929e71da7daf5aeefaef53b5a36_184666_720x0_resize_lanczos_3.png alt class=featured-image></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>This paper proposes a general method for improving the structure and quality of sequences generated by a recurrent neural network (RNN), while maintaining information originally learned from data, as well as sample diversity. An RNN is first pre-trained on data using maximum likelihood estimation (MLE), and the probability distribution over the next token in the sequence learned by this model is treated as a prior policy. Another RNN is then trained using reinforcement learning (RL) to generate higher-quality outputs that account for domain-specific incentives while retaining proximity to the prior policy of the MLE RNN. To formalize this objective, we derive novel off-policy RL methods for RNNs from KL-control. The effectiveness of the approach is demonstrated on two applications; 1) generating novel musical melodies, and 2) computational molecular generation. For both problems, we show that the proposed method improves the desired properties and structure of the generated sequences, while maintaining information learned from data.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#1>Conference paper</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9">In <em>International Conference on Machine Learning (ICML)</em></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tag/sequence-modeling/>Sequence Modeling</a>
<a class="badge badge-light" href=/tag/communication-and-language/>Communication and Language</a>
<a class="badge badge-light" href=/tag/music-generation/>Music Generation</a>
<a class="badge badge-light" href=/tag/drug-discovery/>Drug Discovery</a>
<a class="badge badge-light" href=/tag/healthcare/>Healthcare</a>
<a class="badge badge-light" href=/tag/generalization/>Generalization</a>
<a class="badge badge-light" href=/tag/transfer-learning/>Transfer Learning</a>
<a class="badge badge-light" href=/tag/kl-control/>KL-control</a>
<a class="badge badge-light" href=/tag/reinforcement-learning/>Reinforcement Learning</a>
<a class="badge badge-light" href=/tag/machine-learning/>Machine Learning</a>
<a class="badge badge-light" href=/tag/deep-learning/>Deep Learning</a></div><div class="media author-card content-widget-hr"><a href=https://natashamjaques.github.io/><img class="avatar mr-3 avatar-circle" src=/author/natasha-jaques/avatar_hu04b955ed351a495cc2c1096ede1d3b28_762133_270x270_fill_q75_lanczos_center.jpg alt="Natasha Jaques"></a><div class=media-body><h5 class=card-title><a href=https://natashamjaques.github.io/>Natasha Jaques</a></h5><p class=card-text>My research is focused on Social Reinforcement Learning&ndash;developing algorithms that use insights from social learning to improve AI agents&rsquo; learning, generalization, coordination, and human-AI interaction.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:natashamjaques@gmail.com><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/natashajaques target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.com/citations?hl=en&user=8iCb2TwAAAAJ" target=_blank rel=noopener><i class="fas fa-graduation-cap"></i></a></li><li><a href=https://github.com/natashamjaques target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=/uploads/cv_natasha_jaques.pdf><i class="fas fa-download"></i></a></li></ul></div></div><div class="article-widget content-widget-hr"><h3>Related</h3><ul><li><a href=/publication/social-and-affective-machine-learning/>Social and Affective Machine Learning</a></li><li><a href=/publication/tuning-recurrent-neural-networks-with-reinforcement-learning/>Tuning Recurrent Neural Networks with Reinforcement Learning</a></li><li><a href=/publication/approximating-interactive-human-evaluation-with-selfplay-for-opendomai/>Approximating Interactive Human Evaluation with Self-Play for Open-Domain Dialog Systems</a></li><li><a href=/publication/hierarchical-reinforcement-learning-for-opendomain-dialog/>Hierarchical Reinforcement Learning for Open-Domain Dialog</a></li><li><a href=/publication/multimodal-autoencoder-a-deep-learning-approach-to-filling-in-missing-/>Multimodal Autoencoder: A Deep Learning Approach to Filling in Missing Sensor Data and Enabling Better Mood Prediction</a></li></ul></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>Built using <a href=https://gohugo.io target=_blank rel=noopener>Hugo</a> and the <a href=https://github.com/wowchemy/starter-hugo-academic target=_blank rel=noopener>Wowchemy academic template</a>. View <a href=https://github.com/natashamjaques/professional_website target=_blank rel=noopener>source</a>.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script>
<script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script>
<script src=/en/js/wowchemy.min.26bc5a5b73c468c9e767656a378ac5e3.js></script>
<script async defer src=https://buttons.github.io/buttons.js></script></body></html>