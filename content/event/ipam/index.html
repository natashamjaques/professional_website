---
title: UCLA Institute for Pure and Applied Mathematics (IPAM) Mathematics of Intelligence workshop

event: UCLA Institute for Pure and Applied Mathematics (IPAM) Mathematics of Intelligence workshop
event_url: https://www.youtube.com/watch?v=rjLT0NkCp9I

location: Re-Work
<!-- address:
  street: 450 Serra Mall
  city: Stanford
  region: CA
  postcode: '94305'
  country: United States -->

summary: This talk focuses on how social learning from other agents can lead to learning more complex behaviors and enhance generalization. I discuss PAIRED and recent work on emergent social learning and PsiPhi-Learning in detail. 
abstract: "Social learning helps humans and animals rapidly adapt to new circumstances, and drives the emergence of complex learned behaviors. This talk focuses on how Reinforcement Learning (RL) agents can benefit from social learning in multi-agent environments. First,  I will demonstrate how multi-agent training can be a useful tool for improving learning and generalization. I will present PAIRED, in which an adversary learns to construct training environments to maximize regret between a pair of learners, leading to the generation of a complex curriculum of environments that improve the learnerâ€™s zero-shot transfer to unknown, single-agent test tasks. Second, I will explore social learning in naturalistic multi-agent environments, in which there are other agents that may have relevant knowledge, but they are not explicitly interested in teaching the RL agent (analogous to the autonomous driving setting). I first show that traditional model-free RL algorithms do not benefit from social learning in such contexts, and cannot discover the optimal policy even when nearby agents are visibly following it. I will present a technique for enabling social learning, and demonstrate that agents which successfully engage in social learning can generalize better to new environments. We then introduce an improved method for social learning, PsiPhi-learning, which leverages successor features to create a feedback loop in which individual RL experience improves the ability to model other agents, and modeling other agents improves the ability to take individual actions in RL. PsiPhi-learning improves over both traditional RL techniques and recent imitation learning techniques, flexibly benefitting from learning from other agents when it is relevant to the task at hand."

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: "2022-02-19T13:00:00Z"
#date_end: "2030-06-01T15:00:00Z"
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: "2017-01-01T00:00:00Z"

authors: []
tags: []

# Is this a featured talk? (true/false)
featured: false

image:
  caption: ''
  focal_point: Right

links:
url_code: ""
url_pdf: ""
url_slides: ""
url_video: https://www.youtube.com/watch?v=rjLT0NkCp9I
url_embed: https://www.youtube.com/embed/rjLT0NkCp9I

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: example

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects:
- internal-project
---

{{< youtube rjLT0NkCp9I >}}

